%% ------------------------------------------------------------------------- %%
\chapter{Propriedades Básicas do Processo K}
\label{cap:propriedades}

Nesse capítulo vamos estabelecer resultados que serão ferramentas
básicas para trabalhar com o processo K durante o resto da
dissertação. Como uma maneira de aproximá-lo por processos Markovianos
de salto.

%% ------------------------------------------------------------------------- %%

\section{Observações gerais}
\label{sec:observacoes}

Nessa seção vamos colocar várias proposições ou observações sobre o
processo, que serão usadas à exaustão em seções subsequentes da
dissertação.

\begin{proposicao}
  \label{prop:gamma-crescente}
  $\Gamma$ é \qc estritamente crescente.
\end{proposicao}
\begin{proof}
  Como estamos supondo que $\sum_{x \in \Nz} \lambda_x = \infty$,
  então o conjunto das marcas dos processos de Poisson é \qc densa em
  $\R^+$. Em outras palavras, quase certamente, para todo $0 \leq s <
  t$, teremos que existe um $x \in \Nz$ e $i \geq 1$ tal que $s <
  \sigma^x_i < t$. Dessa forma usando a definição de $\Gamma$, teremos
  que:
  \begin{displaymath}
    \Gamma(t) - \Gamma(s) \geq \gamma_x T^x_i > 0
  \end{displaymath}
\end{proof}

\begin{proposicao}
  \label{prop:gamma-finita}
  Com probabilidade $1$, $\Gamma(t)$ é finito para todo $t \geq 0$.
\end{proposicao}
\begin{proof}
  Usando o teorema da convergência monótona, podemos calcular:
  \begin{displaymath}
    \E \left[\Gamma^y(t) \right] = \gamma_y + t \sum_{x \in \Nz}
    \lambda_x \gamma_x + ct < \infty
  \end{displaymath}
  Assim para cada $t \geq 0$ fixo, teremos que $\Gamma(t)$ é quase
  certamente finito. Tomando uma sequência $t_n \to \infty$ quando $n
  \to \infty$, teremos que $P(\cap_{n = 1}^{\infty} \{ \Gamma^y (t_n)
  < \infty \} \cap \{ \Gamma \textrm{ é crescente}\}) = 1$. Assim para
  realizações dentro desse evento, teremos que para todo $t \geq 0$,
  existe um $n$ tal que $t_n > t$. Portando $\Gamma(t) < \Gamma(t_n) <
  \infty$.
\end{proof}


\begin{proposicao}
  \label{prop:gamma-cadlag}
  A função $\Gamma$ é quase certamente càdlàg. Isso é, é contínua à
  direita e tem limites à esquerda.
\end{proposicao}
\begin{proof}

  Fixemos uma realização de $\Gamma$ onde ela seja crescente e
  limitada em compactos. Vamos pedir ainda que cada processo de
  Poisson $N_x$, $x \in \Nz$ seja localmente finito. Tais realizações
  tem probabilidade $1$.

  O fato de $\Gamma$ ser crescente e limitada em compactos já
  estabelece diretamente a existência dos limites à direita e à
  esquerda. Agora resta mostrar a continuidade à direita.

  Para isso fixe um $t \geq 0$ arbitrário. Para $s > 0$ teremos:

  \begin{equation*}
    \Gamma(t+s) - \Gamma(t) = 
    c s + 
    \sum_{x \in \N} \sum_{i = N_x(t)+1}^{N_x(t+s)} \gamma_x T^x_i.
  \end{equation*}

  Para cada $x$, como $N_x$ é localmente finito, temos que $N_x(t+s) =
  N_x(t)$ para $s$ pequeno o suficiente. Assim quando $s \searrow 0$,
  nós iremos calcular o limite da ``cauda'' de uma série convergente,
  de onde concluímos que:

  \begin{displaymath}
    \lim_{s \searrow 0} \Gamma(t+s) - \Gamma(t) = 0
  \end{displaymath}
\end{proof}


\begin{proposicao}
  \label{prop:reinicia-infinito}
  Para todo $y \in \Nz$ e $t \geq 0$, vale que
  $X^y(t + \gamma_y T_0^y) = X^\infty(t)$.
\end{proposicao}
\begin{proof}
  Fixe um $y \in \Nz$. Primeiramente observe que para todo $s \geq 0$,
  temos que $\Gamma^y(s) = \Gamma^\infty(s) + \gamma_yT^y_0$.

  Fixada uma realização do processo, suponha que $X^\infty(t) = x \in
  \Nz$, assim existe um $i \geq 1$ tal que $\Gamma^\infty(\sigma_i^x-)
  \leq t < \Gamma^\infty(\sigma_i^x)$. Dessa forma, somando $\gamma_y
  T^y_0$ nos termos dessa desigualdade, teremos que
  $\Gamma^y(\sigma_i^x-) \leq t+\gamma_yT_0^y <
  \Gamma^y(\sigma_i^x)$. E portanto $X^y(t+\gamma_y T_0^y) = x$.

  Com raciocínio análogo, chegamos que se $X^y(t+\gamma_y T_0^y) = x
  \in \Nz$, então $X^\infty(t) = x$. De onde concluímos a igualdade desejada.
\end{proof}


\begin{proposicao}
  \label{prop:proc-cadlag}
  O processo K é quase certamente càdlàg.
\end{proposicao}
\begin{proof}

  Iremos mostrar que o processo iniciado no $\infty$ é Càdlàg. Isso
  irá mostrar que o processo é Càdlàg para qualquer condição inicial,
  visto que iniciando em $y$, iremos continuar em $y$ até $\gamma_y
  T^y_0$, e depois continuaremos como uma cópia do processo iniciado no
  $\infty$.

  Fixe uma realização do processo e fixe $T > 0$ e $\epsilon > 0$
  arbitrários. Seguindo \cite{billingsley:99}, vamos mostrar que
  existem $0 = t_0 < t_1 < \ldots < t_N = T$ tais que $w[t_{i-1}, t_i)
  < \epsilon$, para todo $i = 1, \ldots, N$. Onde $w(A) = \sum_{t, s
    \in A} |X^\infty(t) - X^\infty(s)|$ para $A \subseteq \R$.

  Tome um $m \in \Nz$ tal que o $\diam\{x \in \Nzb: x > m \} =
  \frac{1}{m+1} < \epsilon$, onde $\diam(A)$ é o diâmetro do conjunto
  $A$ na métrica \eqref{eq:metrica}.

  Agora tome $S_1 < S_2 < \ldots < S_M$ uma ordenação dos conjunto $\{
  \sigma^x_i: x \in \Nz \,\, i \geq 1 \,\, \Gamma(\sigma^x_i) \leq
  T\}$. Finalmente fixe $N = 2M+1$ se $\Gamma(S_M) < T$ e $N = 2M$
  caso contrário. Tome $t_0 = 0$, $t_N = T$ e para $i=1,\ldots, M$:
  \begin{align*}
    t_{2i-1} &= \Gamma(S_i-)\\
    t_{2i} &= \Gamma(S_i).\\
  \end{align*}

  Se $t \in [\Gamma(S_i-), \Gamma(S_i))$, teremos que
  $X(t)$ é constante, enquanto que se $t \in
  [\Gamma(S_{i-1}), \Gamma(S_{i}-))$, termos que
  $X(t) > m$, assim a variação nesse intervalo é menor ou igual
  à $\frac{1}{m} < \epsilon$. O mesmo ocorre nos intervalos $[t_0,
  t_1)$ e $[t_{N-1}, t_N)$.
\end{proof}

\begin{proposicao}
  \label{prop:proc-descontinuidades}
  $(X(t))_{t\geq 0}$ é \qc contínuo fora de $\{ \Gamma(0),
  \Gamma(\sigma_i^x-), \Gamma(\sigma_i^x): x \in \Nz\}$.
\end{proposicao}
\begin{proof}
  Tome $t$ é um ponto de descontinuidade de $\Gamma$, então $\Gamma(t) -
  \Gamma(t-) > \epsilon > 0$. Fixe um $T > t$ e tome $0 = t_0 < t_1 <
  \ldots < t_N = T$ como na Proposição \ref{prop:proc-cadlag}. Se
  $t \not\in \{t_0, \ldots, t_N\}$, então existe um $i$ tal que $t \in
  (t_i, t_{i+1})$. Assim teremos que $w[t_i, t_{i+1}) \geq \Gamma(t) -
  \Gamma(t-) > \epsilon$, que contraria a nossa escolha de $\{t_0,
  \ldots, t_N\}$.

  Assim temos que $t = t_i$ para algum $i$. Como na proposição
  anterior, escolhemos os $t_i$'s sempre do conjunto proposto, temos
  eles são os únicos candidatos possíveis para pontos de continuidade.
\end{proof}

%% ------------------------------------------------------------------------- %%

\section{Aproximações}
\label{sec:aproximacoes}

Fixado um natural $n \in \Nz$, vamos ``truncar'' nosso processo em
$\{1, 2, \ldots, n, \infty\}$. Depois vamos mostrar mostrar que esses
processos truncados convergem ao processo original.

Primeiramente, para $n \in \Nz$ e $y \in \{1, \ldots, n, \infty\}$,
vamos definir:
\begin{equation}
  \Gamma^{(n)} := \Gamma^{y,(n)}_c (t) = \gamma_y T_0^y
  + \sum_{x =1}^{n} \sum_{i = 1}^{N_x(t)}
  \gamma_x T_i^x
  + ct.
\end{equation}

O processo truncado em $n \in \Nz$, com estado inicial $y \in \{1,
\ldots, n, \infty\}$ será:
\begin{equation}
  X^{(n)}(t) = X^{y,(n)}_c(t) = \begin{cases}
    y, & \textrm{ se }  t < \gamma_y T_0^y\\
    x, & \textrm{ se } \Gamma^{y,(n)}_c(\sigma_i^x-) \leq t <
    \Gamma^{y,(n)}_c(\sigma^x_i)
    \textrm{ para algum } i \\
    \infty, & \textrm{ caso contrário.}
  \end{cases}
\end{equation}

\begin{proposicao}
  O processo $X^{(n)}$ é Càdlàd e Markoviano.
\end{proposicao}
\begin{proof}
  Como visto na seção \ref{sec:visualizacao}, o processo $X_n^y$ é um
  processo Markoviano de saltos, construído para ser contínuo a
  direita.
\end{proof}

Note que nós construímos $\{(X^{(n)}(t))_t\}_{n \in \Nz}$ e $(X(t))_t$
num mesmo espaço de probabilidade. Assim é natural perguntar se
$(X^{(n)}(t))_t$ converge para $(X(t))_t$ de alguma forma.

\begin{teorema}
  \label{teo:convergencia}
  Se considerarmos a topologia introduzida na seção
  \ref{sec:topologia}, então $X^{\infty, (n)} (\bullet) \xrightarrow{n \to
    \infty} X^\infty(\bullet)$ \qc na métrica de Skorohod.
\end{teorema}

A métrica de Skorohod é uma métrica sobre o espaço das trajetórias
Càdlàg que permite pequenas distorções temporais. Como
referência recomendamos \cite{billingsley:99} e \cite{ethier:86}.


\begin{proof}
  Essa demonstração foi adaptada diretamente do \emph{Lema 3.11} de
  \cite{fontes:08}.

  Para provar a proposição, vamos mostrar que o item (c) da proposição
  5.3, capítulo 5 de \cite{ethier:86} vale quase certamente.

  Para essa demonstração, vamos sempre considerar que o processo
  iniciou no $\infty$, e vamos parar de carregar esse índice na notação.

  Fixe um $T > 0$. Para cada natural $m$, considere $\delta_m :=
  \diam\{ x \in \Nzb: x > m \} = \frac{1}{m+1}$. Tome ainda $0 = S_0^m
  < S_1^m < S_2^m < \ldots $ uma ordenação de $\{0\}\cup\{ \sigma^x_i
  : x \leq m, i \geq 1\}$. Considere ainda, para $n \in \Nz$:
  \begin{displaymath}
    L^m_n := \min \left\{ i \geq 1: \Gamma^{(n)}(S^m_i) \geq T \right\}.
  \end{displaymath}

  Como o conjunto $\{\sigma_i^x: x > m, i\geq 1\}$ é denso, temos
  que para $n$ suficientemente grande $\Gamma^{(n)}(S^m_{i+1}-) >
  \Gamma^{(n)}(S^m_i)$ para todo $i < L^m_n$.

  Para esses valores de $n$, defina $\lambda_n^m: [0, L_n^m] \to \R^+$
  da seguinte forma:
  \begin{displaymath}
    \lambda_n^m(t) = \begin{cases}
      \Gamma(S_i^m) + \frac{\Gamma(S_{i+1}^m-) - \Gamma(S_i^m)}
      {\Gamma^{(n)}(S_{i+1}^{(m)} -) - \Gamma^{(n)}(S_i^m)}
      \left[t - \Gamma^{(n)}(S_i^m)\right]
      & \textrm{ se }
      \Gamma^{(n)}(S_i^m) \leq t \leq \Gamma^{(n)}(S_{i+1}^m-) \\
      \Gamma(S_{i+1}^m-) - \Gamma^{(m)}(S_{i+1}^m-) + t
      & \textrm{ se }
      \Gamma^{(n)}(S_{i+1}^m-) \leq t \leq \Gamma^{(n)}(S_{i+1}^m).
    \end{cases}
  \end{displaymath}

  Para entender o que motivou essa definição, observe que para $i = 0,
  \ldots L_n^m$, teremos que:
  \begin{align*}
    \lambda_n^m(\Gamma^{(n)}(S_i^m-)) &= \Gamma(S_i^m-)\\
    \lambda_n^m(\Gamma^{(n)}(S_i^m)) &= \Gamma(S_i^m).
  \end{align*}
  Enquanto que nos pontos interiores, ``completamos'' $\lambda_n^m$ de
  maneira linear.

  Como $\Gamma(t) \geq \Gamma^{(n)}(t)$ para todo $n \in \Nz$, teremos
  que $\lambda(t) \geq t$. Usando a linearidade por partes, e o fato
  que $\Gamma(\sigma^x_i) = \Gamma(\sigma_i^x-) + \gamma_x T^x_i$,
  teremos que:
  \begin{displaymath}
    \sup_{0 \leq t \leq T} |\lambda_n^m(t) - t| =
    \max_{0 \leq i \leq L_n^m} \{ \Gamma(S_i^m) -
    \Gamma^{(n)}(S_i^m)\}.
  \end{displaymath}
  Essa quantidade converge quase certamente à zero se mantivermos o
  $m$ fixo e jogarmos o $n$ para infinito. Assim para cada $m$ existe
  um $n_m$ tal que para $n \geq n_m$ vale que:
  \begin{displaymath}
    \sup_{0 \leq t \leq T} |\lambda_n^m(t) - t| < \delta_m.
  \end{displaymath}
  Podemos tomar a sequência $(n_m)_{m \geq 1}$ de modo que ela seja
  crescente. Agora vamos ``invertê-la'', isso é, para cada n em $\Z
  \cap [n_{i-1}, n_i)$, defina $m_n = i$. Teremos que:
  \begin{displaymath}
    \sup_{0 \leq t \leq T} |\lambda_n^{m_n}(t) - t| < \delta_{m_n}.
  \end{displaymath}
  Ainda como, para cada $m$ fixado, $n_m$ é finito, vale que $m_n$ vai
  ao infinito quando $n \to \infty$.
  
  Agora note que $t \in [\Gamma^{(n)}(S_{i}^m-),
  \Gamma^{(n)}(S_{i}^m))$ se e somente se $\lambda_n^m(t) \in
  [\Gamma(S_{i}^m-), \Gamma(S_{i}^m))$. Assim $X(\lambda_n^m(t)) \leq
  m$ se e somente se $X^{(n)}(t) \leq m$. De onde concluímos que:
  \begin{displaymath}
    \sup_{0 \leq t \leq T} d\left(X(\lambda_n^m(t)), X^{(n)}\right)
    \leq \delta_m
  \end{displaymath}

  Assim tomando $\tilde{\lambda}_n = \lambda_n^{m_n}$, concluímos que
  quase certamente:
  \begin{align*}
    \sup_{0 \leq t \leq T} |\tilde{\lambda}_n(t) - t|
    &\xrightarrow{n\to\infty} 0 \\
    \sup_{0 \leq t \leq T} d(X(\tilde{\lambda}_n(t)), X^{(n)}(t))
    &\xrightarrow{n\to\infty} 0 \\
  \end{align*}
\end{proof}

\begin{corolario}
  \label{cor:convergencia}
  Para todo $y \in \Nzb$, teremos que  $X^{y, (n)}$ converge \qc para
  para $X^y$ na métrica de Skorohod. Essa convergência é uniforme em
  $y$.
\end{corolario}
\begin{proof}
  Fixado um $T > 0$, tome $\lambda_n: [0, \infty) \to [0, \infty)$
  funções contínuas crescentes tais que quase certamente:
  \begin{gather*}
    \sup_{0 \leq t \leq T} |\lambda_n(t) - t|
    \xrightarrow{n\to\infty} 0 \\
    \sup_{0 \leq t \leq T} d(X^\infty(\lambda_n(t)), X^{\infty, (n)}(t))
    \xrightarrow{n\to\infty} 0 \\
  \end{gather*}

  Para $y \in \Nz$, defina:
  \begin{displaymath}
    \lambda_n^y(t) = \begin{cases}
      t & \textrm{ se } t < \gamma_y T_0\\
      \gamma_yT_0 + \lambda_n(t - \gamma_y T_0) & \textrm{ c.c.}
    \end{cases}
  \end{displaymath}

  Usando a Proposição \ref{prop:reinicia-infinito}, teremos que:
 \begin{gather*}
   \sup_{0 \leq t \leq T} |\lambda_n^y(t) - t| =
    \sup_{0 \leq t \leq T} |\lambda_n(t) - t|
    \xrightarrow{n\to\infty} 0 \\
    \sup_{0 \leq t \leq T} d(X^y(\lambda_n^y(t)), X^{y, (n)}(t)) \leq
    \sup_{0 \leq t \leq T} d(X^\infty(\lambda_n(t)), X^{\infty, (n)}(t))
    \xrightarrow{n\to\infty} 0 \\
  \end{gather*}
\end{proof}

%% ------------------------------------------------------------------------- %%

\section{Propriedade de Markov}
\label{sec:prop-markov}


\begin{proposicao}
  \label{prop:quase-prop-feller}
  Para todo $t > 0$, teremos que $\lim_{y \to \infty} X^y(t) =
  X^\infty(t)$  \qc.
\end{proposicao}
\begin{proof}
  Fixe um $t > 0$ e uma realização do processo. Como estamos supondo
  que $\gamma_y \xrightarrow{y\to\infty} 0$, então podemos supor que
  $\gamma_y T_0 < t$. Assim, usando a Proposição
  \ref{prop:reinicia-infinito}, teremos que:
  \begin{displaymath}
    |X^y(t) - X^\infty(t)| = |X^\infty(t-\gamma_yT_0) - X^\infty(t)|.
  \end{displaymath}

  Agora, pela Proposição \ref{prop:proc-descontinuidades}, teremos que
  todo $t > 0$ fixado é \qc um ponto de continuidade do processo,
  portando como $\gamma_y T_0 \xrightarrow{y \to \infty} 0$ \qc, temos
  que a quantidade acima converge à zero \qc. 
\end{proof}



\begin{definicao}
  \label{def:semigrupo}
  Denotaremos por $\Psi$ e $\Psi^n$ os semigrupos de transição de $X$
  e $X^{(n)}$ respectivamente, isso é, para $t > 0$ e $f: \Nzb \to
  \R$:
  \begin{gather*}
    \Psi_t f (x) = \E \left[ X^x(t) \right]\\
    \Psi^n_t f (x) = \E \left[ X^{x, (n)}(t) \right]
  \end{gather*}
\end{definicao}

\begin{proposicao}
  \label{prop:proriedade-feller}
  Se $f: \Nzb \to \R$ é uma função contínua, então para todo $t > 0$,
  $\Psi_t f$ também é uma função contínua.
\end{proposicao}
\begin{proof}
  Fixe um $t > 0$ arbitrário. Pela Proposição
  \ref{prop:quase-prop-feller}, teremos que $X^y(t)
  \xrightarrow{y\to\infty} X^\infty(t)$ \qc. Como $f$ é contínua,
  teremos que $f(X^y(t)) \xrightarrow{y\to\infty} f(X^\infty(t))$ \qc.

  O espaço $\Nzb$ é compacto, e como $f$ é contínua, ela é também
  limitada. Assim usando o teorema da convergência dominada, teremos
  que:
  \begin{displaymath}
    \Psi_t f (y) = \E \left[ f(X^y(t)) \right]
    \xrightarrow{y\to\infty}
    \E \left[ f(X^\infty(t)) \right] = \Psi_t f (\infty),
  \end{displaymath}
  de onde concluímos que $\Psi_t f$ é uma função contínua.
\end{proof}

\begin{teorema}
  \label{teo:proc_markov}
  O processo K é um processo Markoviano.
\end{teorema}

\begin{proof}

  Essa demonstração é uma leve adaptação da demonstração da segunda
  parte da Proposição (3.6) de \cite{fontes:08}.

  Fixado um $m \geq 1$, $t_1 < t_2 < \ldots < t_{m+1}$ e $f_1, \ldots,
  f_{m+1} : \Nzb \to \R$ funções contínuas.

  Como $X^{(n)}$ é Markoviano, teremos que:
  \begin{gather}
    \label{eq:markov-truncado}
    \E \left[
      f_{1}(X^{(n)}(t_{1})) 
      \ldots
      f_{m}(X^{(n)}(t_{m})) 
      f_{m+1}(X^{(n)}(t_{m+1})) 
    \right] \notag\\
    = \E \left[
      f_{1}(X^{(n)}(t_{1})) 
      \ldots
      f_{m}(X^{(n)}(t_{m})) 
      \Psi^n_{t_{m+1} - t{m}} f_{m+1} (X^{(n)}(t_{m})) 
    \right]
  \end{gather}

  A Proposição \ref{prop:proc-descontinuidades} nos garante que \qc
  $t_1, \ldots, t_{m+1}$ são pontos de continuidade do processo, e
  como convergência na métrica de Skorohod garante convergência
  pontual nos pontos de continuidade, teremos que $f_i(X^{(n)}(t_i)) \to
  f_i(X(t_i))$ \qc já que $f_i$ é contínua.

  Temos ainda que $f_1, \ldots f_{m+1}$ são limitadas porque são
  funções contínuas num espaço compacto. Assim usando o teorema da
  convergência dominada, teremos que a parte da esquerda de
  \eqref{eq:markov-truncado} converge para:
  \begin{displaymath}
    \E \left[
      f_{1}(X(t_{1})) 
      \ldots
      f_{m}(X(t_{m})) 
      f_{m+1}(X(t_{m+1})) 
    \right]
  \end{displaymath}

  Agora vamos estimar a parte da direita por:
  \begin{displaymath}
    \E \left[
      f_{1}(X (t_{1})) 
      \ldots
      f_{m}(X (t_{m})) 
      \Psi_{t_{m+1} - t{m}} f_{m+1} (X (t_{m})) 
    \right] + \epsilon_n
  \end{displaymath}

  Agora usando o fato de $f_1, \ldots, f_m$ serem limitadas, teremos
  que para alguma constante $K$:
  \begin{displaymath}
    |\epsilon_n| \leq  K \sup_{y \in \Nzb} \left\lvert
      \Psi^n_{t_{m+1}-t_m} f_{m+1} (y) - 
      \Psi_{t_{m+1}-t_m} f_{m+1} (y) 
    \right\rvert
  \end{displaymath}

  Apenas para simplificar a notação, vamos denotar por $s = t_{m+1} -
  t_m$ e $g = f_{m+1}$. Assim teremos que:
  \begin{align*}
    \Psi^n_{s} g (y) - \Psi_{s} g (y)
    &= \E \left[g(X^{y, (n)}(s)) - g(X^y(s)) \right] \notag \\
    &= \E \left[g(X^{y, (n)}(s)) - g(X^y(\lambda_n^y(s))) \right]
    + \E \left[g(X^y(\lambda_n^y(s))) - g(X^y(s)) \right],
  \end{align*}
  onde $\lambda_n^y$ são tomadas como no Corolário
  \ref{cor:convergencia}, para um $T > s$ qualquer.

  Dessa maneira, temos que:
  \begin{align}
    \label{eq:esperancas-markov}
    |\epsilon_n| &\leq 
    K \sup_{y\in\Nzb}\left\lvert
      \E \left[g(X^{y, (n)}(s)) - g(X^y(\lambda_n^y(s))) \right]
    \right\rvert
    + K \sup_{y\in\Nzb}\left\lvert
      \E \left[g(X^y(\lambda_n^y(s))) - g(X^y(s)) \right]
    \right\rvert. 
  \end{align}

  Vamos tratar os dois termos dessa soma separadamente.

  Por construção das $\lambda_n^y$, temos que para todo $y$, quase certamente:
  \begin{displaymath}
    d(X^{y, (n)}(s), X^y(\lambda_n^y(s)) \leq
    d(X^{\infty, (n)}(s), X^y(\lambda_n^\infty(s))
    \xrightarrow{n\to\infty} 0.
  \end{displaymath}

  $g$ é uma função contínua em um espaço compacto, assim ela é
  uniformemente contínua. Isso é, para todo $\epsilon > 0$, existe um
  $\delta_\epsilon > 0$ tal que se $d(x, y) < \delta_\epsilon$ então
  $|g(x)-g(y)| < \epsilon$.

  Dessa forma, fixado um $\epsilon > 0$ arbitrário, teremos que:
  \begin{gather*}
    \sup_{y\in\Nzb} \left\lvert \E \left[ g(X^{y,(n)}(s)) -
        g(X^{y}(\lambda_n^y)) \right]
    \right\rvert\\
    \leq \sup_{y\in\Nzb} \left\lvert \E \left[ \left(g(X^{y,(n)}(s)) -
          g(X^{y}(\lambda_n^y)) \right) \ind\{ d(X^{y, (n)}(s),
        X^y(\lambda_n^y(s)) < \delta_\epsilon \} \right]
    \right\rvert \\
    + 2\Vert g \Vert \sup_{y \in \Nzb} P\left( d(X^{y, (n)}(s),
      X^y(\lambda_n^y(s)) \geq
      \delta_\epsilon \right) \\
    \leq \epsilon + 2 \Vert g \Vert P \left( d(X^{\infty, (n)}(s),
      X^\infty(\lambda_n^\infty(s)) \geq \delta_\epsilon \right).
  \end{gather*}
  Essa última quantidade vai para $\epsilon$ quando $n\to
  \infty$. Como $\epsilon$ foi escolhido arbitráriamente, concluímos
  que o primeiro termo de \eqref{eq:esperancas-markov} converge à
  zero.

  Para calcular o segundo termo, veja que aquela quantidade, para cada
  $y$ fixado, vai à zero, já que $s$ é \qc um ponto de continuidade do
  processo. Dessa forma existe uma sequência $(k_n)$ tal que $k_n
  \xrightarrow{n\to\infty} \infty$ onde:
  \begin{displaymath}
      \max_{y \leq k_n} \left\lvert
      \E \left[g(X^y(\lambda_n^y(s))) - g(X^y(s)) \right]
    \right\rvert \xrightarrow{n\to \infty} 0.
  \end{displaymath}

  Agora vamos tomar $\delta_n = \sqrt{\sup_{y > k_n}\gamma_y}$. Já
  que $\gamma_y \xrightarrow{y\to\infty} 0$, então temos que $\delta_n
  \xrightarrow{n\to\infty} 0$ e  $\sup_{y > k_n} P(\gamma_y T_0 > \delta_n) = 
  e^{-\frac{1}{\delta_n}} \xrightarrow{n\to\infty} 0$.

  Como $\delta_n \to 0$, vamos apenas considerar $n$ suficientemente
  grande, de forma que $\delta_n < s \leq \lambda_n^y(s)$. Usando a Proposição
  \ref{prop:reinicia-infinito} e condicionando em $\gamma_yT_0 <
  \delta_n$, teremos que:
  \begin{align}
    \label{eq:markov-quase-la}
    \sup_{y > k_n}& \left\lvert \E \left[g(X^y(\lambda_n^y(s))) -
        g(X^y(s)) \right]
    \right\rvert \notag \\
    &\leq \sup_{y > k_n} \E \left\lvert
      \left[g(X^\infty(\lambda_n^y(s)-\gamma_yT_0)) -
        g(X^\infty(s-\gamma_yT_0)) \right] \ind\{ \gamma_yT_0 <
      \delta_n \}
    \right\rvert\\
    &+ 2 \Vert g \Vert \sup_{y > k_n} P(\gamma_y T_0 > \delta_n).
    \notag
  \end{align}

  Nós escolhemos $\delta_n$ de forma que o segundo termo dessa soma vá
  à zero quando $n \to \infty$. Agora repare que podemos dominar o
  primeiro termo por:
  \begin{displaymath}
     \E \left\lvert \sup_{y > k_n}
      \sup_{0 \leq t \leq \delta_n} \left[
        g(X^\infty(\lambda_n^y(s)-t)) -
        g(X^\infty(s-t))
      \right] 
    \right\rvert.
  \end{displaymath}

  Note que a variável sobre a qual estamos tomando esperança é
  dominada por $2\Vert g \Vert$. Portando se mostrarmos que ela
  converge \qc para zero, valerá que sua esperança também vai a zero.

  Fixado um $\epsilon > 0$, tome $\epsilon^\prime > 0$ tal que $d(x, y) <
  \epsilon^\prime$ implique que $|g(x) - g(y)| < \epsilon$, isso
  existe por causa da continuidade uniforme de $g$.
 
  Como $s$ é \qc um ponto de continuidade de $X^\infty$, existe um
  $\epsilon^{\prime\prime}$ tal que se $|t| <
  \epsilon^{\prime\prime}$, então $d(X_{s}, X_{s+t}) < \frac{\epsilon^{\prime}}{2}$.

  Assim se tomarmos $n_0$ tal que para todo $n > n_0$, $\delta_{n} <
  \frac{\epsilon^{\prime\prime}}{2}$ e $\sup_{0 \leq t \leq T}
  |\lambda_n(t) - t| < \frac{\epsilon^{\prime\prime}}{2}$, teremos
  que, para todo $y\in\Nzb$ e $t \leq \delta_n$:
  \begin{gather*}
    |\lambda_n^y(s) - t - s| < \epsilon^{\prime\prime}\\
    |s - t - s | < \epsilon^{\prime\prime}
  \end{gather*}
  
  Portanto temos que:
  \begin{displaymath}
    d(X^\infty(\lambda_n^y(s)-t), X^\infty(s-t)) \leq
     d(X^\infty(\lambda_n^y(s)-t), X^\infty(s))+
     d(X^\infty(s), X^\infty(s-t))
     < \epsilon^{\prime}
  \end{displaymath}

  De onde finalmente concluímos que para todo $n > n_0$:
  \begin{displaymath} 
    \sup_{y > k_n}
    \sup_{0 \leq t \leq \delta_n} \left[
      g(X^\infty(\lambda_n^y(s)-t)) -
      g(X^\infty(s-t))
    \right] < \epsilon
  \end{displaymath}

  Como o $\epsilon$ foi tomado arbitrariamente, concluímos que essa
  quantidade vai a zero quase certamente.


  Juntando tudo, provamos que $\epsilon_n \to 0$ quando $n \to
  \infty$, de onde concluímos que:
  \begin{displaymath}
    \E \left[
      f_{1}(X(t_{1})) 
      \ldots
      f_{m}(X(t_{m})) 
      f_{m+1}(X(t_{m+1})) 
    \right] \notag\\
    = \E \left[
      f_{1}(X(t_{1})) 
      \ldots
      f_{m}(X(t_{m})) 
      \Psi_{t_{m+1} - t{m}} f_{m+1} (X(t_{m})) 
    \right].
  \end{displaymath}
\end{proof}




\begin{corolario}
  \label{cor:proc_fort_markov}
  $X^y$ é fortemente Markoviano.
\end{corolario}
\begin{proof}
  Um processo de Fel ler Markoviano é fortemente Markoviano. Ver (???)
\end{proof}



%%% Local Variables: 
%%% TeX-master: "tese"
%%% End: 
